{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69e28fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dbed5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "import yaml\n",
    "import uuid\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19581ff2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_paths(location, models_list, brigade):\n",
    "    \n",
    "    '''\n",
    "    Функція знаходить шляхи до файлів з результатами (directory /wfv_result/) для кожної бригади та моделі\n",
    "    \n",
    "    Повертає список з гіперпараметрами кожної моделі по кожній бригаді (model_parameters_pred), \n",
    "    а також список з шляхами до усіх файлів з результатами усіх експериментів по бригаді (file_paths)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    uuids = []\n",
    "    model_names = []\n",
    "    train_start_or_duration = []\n",
    "    hyperparameters = []\n",
    "    features = []\n",
    "    n_models = []\n",
    "    \n",
    "    paths_to_predictions = []\n",
    "    paths_to_info = []\n",
    "\n",
    "    file_paths_to_prediction = []\n",
    "    file_paths_to_info = []\n",
    "    \n",
    "    for model in models_list:\n",
    "        if location == 'vpf':\n",
    "            paths_to_predictions += glob(f'/datalake/mhp/{location}/gr/{brigade}/ecf/forecast/{model}/research_task_*/{model}_*')\n",
    "            paths_to_info += glob(f'/datalake/mhp/{location}/gr/{brigade}/ecf/wfv_result/{model}/research_task_*')\n",
    "        elif location == 'mpf':\n",
    "            paths.extend(glob(f'/datalake/mhp/{location}/gr/ecf/wfv_result/{model}/research_task_*'))\n",
    "            \n",
    "#     print(paths_to_predictions, paths_to_info)\n",
    "\n",
    "    for path2 in paths_to_info:   \n",
    "#     for path2 in [max(paths_to_info, key=os.path.getctime)]:   # тільки для останнього експерименту\n",
    "        file_paths_to_info.extend(glob(os.path.join(path2, '*.csv')))\n",
    "\n",
    "\n",
    "    for path2 in paths_to_predictions:\n",
    "#     for path2 in [max(paths_to_predictions, key=os.path.getctime)]:   # тільки для останнього експерименту\n",
    "        prediction_paths = glob(os.path.join(path2, f'*_{location}_d2_*.txt'))\n",
    "        if len(prediction_paths) > 0:\n",
    "            file_paths_to_prediction.append(prediction_paths)\n",
    "\n",
    "    yaml_file_paths = [f.replace('.csv', '.yaml') for f in file_paths_to_info]\n",
    "\n",
    "\n",
    "    for file in yaml_file_paths: \n",
    "        with open(file, 'r') as f:\n",
    "            res = yaml.safe_load(f)\n",
    "        if ('standard_weight' in res['train_features']) and ('total_weight' in res['train_features']) and ('chickens_in_house' in res['train_features']):\n",
    "            uuids.append(res['unique_uuid'])\n",
    "            model_names.append(res['model_name'])\n",
    "            hyperparameters.append(res['model_hyperparameters'])\n",
    "            features.append(res['train_features'])\n",
    "            if 'duration_training_history' in res:\n",
    "                train_start_or_duration.append(res['duration_training_history'])\n",
    "            else:\n",
    "                train_start_or_duration.append(res['train_start'])\n",
    "        else:\n",
    "            continue\n",
    "           \n",
    "        \n",
    "    info_files = []\n",
    "    forecast_files = []\n",
    "    for idx in range(len(uuids)):\n",
    "        exp = f\"{model_names[idx]}_{uuids[idx]}\"\n",
    "        for path_idx in range(len(file_paths_to_info)):\n",
    "            if exp in file_paths_to_info[path_idx]:\n",
    "                info_files.append(file_paths_to_info[path_idx])\n",
    "                forecast_files.append(file_paths_to_prediction[path_idx])\n",
    "                \n",
    "    file_paths_to_info = info_files\n",
    "    file_paths_to_prediction = forecast_files\n",
    "                \n",
    "          \n",
    "    for info_file in file_paths_to_info:\n",
    "        _df = pd.read_csv(info_file)\n",
    "        if f'd2_abs_error_hour_00' in _df.columns:\n",
    "            n_models.append(f\"24 (hourly)\")    \n",
    "        else: \n",
    "            n_models.append(f\"1 (daily)\")\n",
    "\n",
    "    shorten_uuids = [\"-\".join([n.split('-')[0], n.split('-')[-2]]) for n in uuids]\n",
    "\n",
    "    model_parameters = list(zip(uuids, shorten_uuids, model_names, train_start_or_duration, hyperparameters, features, n_models))           \n",
    "\n",
    "\n",
    "    file_paths_splited = [file_paths_to_info[k].split('-') for k in range(len(file_paths_to_info))]\n",
    "    model_name = [file_paths_splited[k][-5].split('\\\\')[1] for k in range(len(file_paths_to_info))]\n",
    "    experiment_names = [\"-\".join([model_name[k], file_paths_splited[k][-2]]) for k in range(len(file_paths_to_info))]     \n",
    "\n",
    "    return file_paths_to_prediction, file_paths_to_info, yaml_file_paths, model_parameters, experiment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c57adb2",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calculate_pred_cons(location, brigade, file_paths_to_prediction, experiment_names):\n",
    "    \n",
    "    '''\n",
    "    Тут створюється датафрейм прогнозованим споживанням для бригади по годинам (дні по індексу, години по колонкам)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    dateparse = lambda dates: datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "    path_to_consumption = f'/datalake/mhp/{location}/gr/{brigade}/ecf/processed_data/hour_consumption_{brigade}.csv'\n",
    "\n",
    "    consumption = pd.read_csv(\n",
    "        path_to_consumption,\n",
    "        parse_dates=['date_time'],\n",
    "        index_col='date_time', \n",
    "        date_parser=dateparse\n",
    "    )\n",
    "    consumption.columns=['hour_consumption']\n",
    "    \n",
    "    \n",
    "    df_preds = consumption.copy()\n",
    "    \n",
    "    for num_exp, exp_paths in enumerate(file_paths_to_prediction):\n",
    "        for d, day_pred in enumerate(exp_paths):\n",
    "            exp_name = experiment_names[num_exp]\n",
    "            day_date = day_pred.split('\\\\')[-1].split('_')[-2]\n",
    "#             print(brigade, day_date)\n",
    "            \n",
    "            with open(day_pred, 'r') as file:\n",
    "                predictions_by_day = np.array([int(k) for k in file.readlines()[0].split(':')[2:-1]])\n",
    "\n",
    "            for h in range(24):\n",
    "                df_preds.loc[pd.to_datetime(day_date) + timedelta(hours=h), f'{exp_name}'] = predictions_by_day[h]\n",
    "                   \n",
    "    df_preds = df_preds.dropna()\n",
    "#     print(df_preds)\n",
    "            \n",
    "    df_preds = df_preds.loc['2022-01-01':'2022-10-19'].drop(df_preds[df_preds['hour_consumption'].isna()].index)\n",
    "    print(df_preds)\n",
    "    \n",
    "    return df_preds, df_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f7b81d",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def form_pred_consumption_df(df_preds, len_df_pred, exp_name):\n",
    "\n",
    "    df_pred_consumption = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len_df_pred, 24):\n",
    "        for h in range(24):\n",
    "            try:\n",
    "                df_pred_consumption.loc[df_preds.index[i].date(), [f\"prediction_{h:02d}\"]] = df_preds.loc[df_preds.index[i]+timedelta(hours=h), f'{exp_name}']\n",
    "            except KeyError:\n",
    "                df_pred_consumption.loc[df_preds.index[i].date(), [f\"prediction_{h:02d}\"]] = 0\n",
    "            \n",
    "\n",
    "    df_pred_consumption = df_pred_consumption.drop(df_pred_consumption[df_pred_consumption==0].dropna().index)\n",
    "    \n",
    "    return df_pred_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be791c1",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def calculate_real_cons_df(location, brigade, df_preds, len_df_pred):\n",
    "    \n",
    "    '''\n",
    "    Тут створюється датафрейм фактичним споживанням для бригади по годинам (дні по індексу, години по колонкам)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df_real_consumption = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, len_df_pred, 24):\n",
    "        for h in range(24):\n",
    "            try:\n",
    "                df_real_consumption.loc[df_preds.index[i].date(), [f\"real_consumption_{h:02d}\"]] = df_preds.loc[df_preds.index[i]+timedelta(hours=h), 'hour_consumption']\n",
    "            except KeyError:\n",
    "                df_real_consumption.loc[df_preds.index[i].date(), [f\"real_consumption_{h:02d}\"]] = 0\n",
    "    \n",
    "\n",
    "    return df_real_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9caf7373",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_errors_dataframe(exp_num, df_pred_consumption, df_real_consumption, df_pred_median, df_pred_mean, df_pred_q25, df_pred_q75, file_paths_to_info, model_parameters, exp_name):\n",
    "    \n",
    "    '''\n",
    "    Функція приймає повернуті значення попередньої функції (набір параметрів та шляхи до файлів)\n",
    "    Повертає датафрейми з: середнім значенням, медіаною, 25-% та 75-% квантилі абсолютної та відносної помилок для кожного експерименту\n",
    "    Якщо експеримент був погодинний (24 моделі на день), вищезазначені значення помилок вказуються для кожної години\n",
    "    \n",
    "    P.S. у набір параметрів додається значення кількості моделей на день (якщо прогноз поденний - 1 модель, якщо погодинний - 24 моделі) \n",
    "    \n",
    "    '''    \n",
    "    \n",
    "    pred = df_pred_consumption.values\n",
    "    orig = df_real_consumption.values\n",
    "\n",
    "    abs_errors = abs(orig-pred)\n",
    "    relative_errors = abs(pred / orig - 1) * 100\n",
    "\n",
    "    abs_err_df = pd.DataFrame(abs_errors, columns=[f'hour_{h:02d}' for h in range(24)])\n",
    "    relative_err_df = pd.DataFrame(relative_errors, columns=[f'hour_{h:02d}' for h in range(24)])\n",
    "        \n",
    "        \n",
    "    df_pred_median.loc[exp_num, 'idx'] = exp_name\n",
    "    df_pred_mean.loc[exp_num, 'idx'] = exp_name\n",
    "    df_pred_q25.loc[exp_num, 'idx'] = exp_name\n",
    "    df_pred_q75.loc[exp_num, 'idx'] = exp_name\n",
    "\n",
    "    df_pred_median.loc[exp_num, f'd2_mean_abs_error'] = abs_err_df.median().values.mean()\n",
    "    df_pred_median.loc[exp_num, f'd2_mean_relative_error'] = relative_err_df.median().values.mean()\n",
    "\n",
    "    df_pred_mean.loc[exp_num, f'd2_mean_abs_error'] = abs_err_df.mean().values.mean()\n",
    "    df_pred_mean.loc[exp_num, f'd2_mean_relative_error'] = relative_err_df.mean().values.mean()\n",
    "\n",
    "    df_pred_q25.loc[exp_num, f'd2_mean_abs_error'] = abs_err_df.quantile(0.25).values.mean()\n",
    "    df_pred_q25.loc[exp_num, f'd2_mean_relative_error'] = relative_err_df.quantile(0.25).values.mean()\n",
    "\n",
    "    df_pred_q75.loc[exp_num, f'd2_mean_abs_error'] = abs_err_df.quantile(0.75).values.mean()\n",
    "    df_pred_q75.loc[exp_num, f'd2_mean_relative_error'] = relative_err_df.quantile(0.75).values.mean()\n",
    "    \n",
    "    return df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ecdeac6",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def final_df_vpf_best_exp_by_day(location, brigade, models_list, df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75, model_parameters, sum_brigades_statistics_uuid):\n",
    "    \n",
    "    '''\n",
    "    Тут формується датафрейм з результатами по двом найкращим експериментам по бригаді (по одному експерименту на кожну модель)\n",
    "    Ці дві моделі для кожної бригади також передаються у текстовий файл best_models_by_brigade.txt, \n",
    "    який буде далі використовуватись при складанні графіків сумарного споживання усіх бригад\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df_final_best_vpf_by_day = pd.DataFrame()\n",
    "    \n",
    "    exp_uuid = []\n",
    "    exp_model = []\n",
    "    train_start_or_duration = []\n",
    "    model_hyperparameters = []\n",
    "    train_features = []\n",
    "    n_models_per_day = []\n",
    "\n",
    "    idx = []\n",
    "    \n",
    "\n",
    "    for n_model, model in enumerate(models_list):\n",
    "        \n",
    "        experiment_names = []\n",
    "        \n",
    "        for model_idx in df_pred_median.index:\n",
    "            if model in str(model_idx):\n",
    "                experiment_names.append(model_idx)\n",
    "            \n",
    "        \n",
    "        best_median_pred_model = df_pred_median.loc[experiment_names, ['d2_mean_abs_error', 'd2_mean_relative_error']]\n",
    "        \n",
    "        best_model_experimental = best_median_pred_model[best_median_pred_model == best_median_pred_model.min()].T.iloc[1].dropna().index[0]\n",
    "        best_mean_value_experimental = df_pred_mean.loc[best_model_experimental, ['d2_mean_abs_error', 'd2_mean_relative_error']]\n",
    "        best_median_value_experimental = df_pred_median.loc[best_model_experimental, ['d2_mean_abs_error', 'd2_mean_relative_error']]\n",
    "        best_q25_value_experimental = df_pred_q25.loc[best_model_experimental, ['d2_mean_abs_error', 'd2_mean_relative_error']]\n",
    "        best_q75_value_experimental = df_pred_q75.loc[best_model_experimental, ['d2_mean_abs_error', 'd2_mean_relative_error']]\n",
    "\n",
    "        \n",
    "        shorten_best_model_uuid = best_model_experimental.split('_')[-1]\n",
    "        for n in model_parameters:\n",
    "            if shorten_best_model_uuid==n[1]:\n",
    "                exp_uuid = n[0]\n",
    "                exp_model = n[2]\n",
    "                train_start_or_duration = n[3]\n",
    "                model_hyperparameters = n[-3]\n",
    "                train_features = n[-2]\n",
    "                n_models_per_day = n[-1]\n",
    "                \n",
    "        idx = f\"{model}-{shorten_best_model_uuid}\"\n",
    "        \n",
    "\n",
    "\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'idx'] = idx\n",
    "        df_final_best_vpf_by_day.loc[n_model, f'mean_abs_value_{len_df_pred}'] = np.around(best_mean_value_experimental['d2_mean_abs_error'], 4)\n",
    "        df_final_best_vpf_by_day.loc[n_model, f'mean_relative_value_{len_df_pred}'] = np.around(best_mean_value_experimental['d2_mean_relative_error'], 4)\n",
    "\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'median_abs_value'] = np.around(best_median_value_experimental['d2_mean_abs_error'], 4)\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'median_relative_value'] = np.around(best_median_value_experimental['d2_mean_relative_error'], 4)\n",
    "\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'q25_abs_value'] = np.around(best_q25_value_experimental['d2_mean_abs_error'], 4)\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'q25_relative_value'] = np.around(best_q25_value_experimental['d2_mean_relative_error'], 4)\n",
    "\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'q75_abs_value'] = np.around(best_q75_value_experimental['d2_mean_abs_error'], 4)\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'q75_relative_value'] = np.around(best_q75_value_experimental['d2_mean_relative_error'], 4)\n",
    "\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'exp_model'] = exp_model\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'n_models_per_day'] = n_models_per_day\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'train_start/duration'] = train_start_or_duration\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'model_hyperparameters'] = f\"{model_hyperparameters}\"\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'train_features'] = f\"{train_features}\"\n",
    "        df_final_best_vpf_by_day.loc[n_model, 'exp_uuid'] = exp_uuid\n",
    "        \n",
    "\n",
    "    df_final_best_vpf_by_day = df_final_best_vpf_by_day.set_index('idx')\n",
    "    \n",
    "    with open(os.path.join(f'/datalake/mhp/{location}/gr/sum_brigades/statistical_result', \n",
    "                           f'best_models_by_brigade_{sum_brigades_statistics_uuid}.txt'), 'a') as file:\n",
    "        for i in range(df_final_best_vpf_by_day.shape[0]):\n",
    "            md = df_final_best_vpf_by_day.iloc[i]\n",
    "            file.writelines(f\"{brigade}-{md['exp_model']}: {md['exp_model']}_{md['exp_uuid']}\\n\")\n",
    "\n",
    "    df_final_best_vpf_by_day.to_csv(os.path.join(f'/datalake/mhp/{location}/gr/{brigade}/ecf/statistical_result', \n",
    "                                    f'(best_model_by_day)_statistical_result_{location}_{brigade}_{datetime.now().strftime(\"%Y%m%d\")}.csv'))\n",
    "\n",
    "    return df_final_best_vpf_by_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d9effa8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def final_df_vpf_all_exp_by_day(location, brigade, df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75, model_parameters):\n",
    "    \n",
    "    '''\n",
    "    Тут формується датасет зі значеннями помилок усіх експериментів по бригадам\n",
    "\n",
    "    '''\n",
    "\n",
    "    exp_uuid = []\n",
    "    exp_model = []\n",
    "    train_start_or_duration = []\n",
    "    model_hyperparameters = []\n",
    "    train_features = []\n",
    "    n_models_per_day = []\n",
    "\n",
    "    models = df_pred_mean['d2_mean_abs_error'].index.dropna()\n",
    "    print(models)\n",
    "\n",
    "    shorten_best_model_uuid = [n.split('_')[-1] for n in models]\n",
    "\n",
    "    #     print(shorten_best_model_uuid)\n",
    "    for m in shorten_best_model_uuid:  \n",
    "        for n in model_parameters:\n",
    "            if m==n[1]:\n",
    "                exp_uuid.append(n[0])\n",
    "                exp_model.append(n[2])\n",
    "                train_start_or_duration.append(n[3])\n",
    "                model_hyperparameters.append(n[-3])\n",
    "                train_features.append(n[-2])\n",
    "                n_models_per_day.append(n[-1])\n",
    "\n",
    "    print(len(model_parameters), df_pred_mean.loc[models, 'd2_mean_abs_error'].dropna().shape[0])\n",
    "\n",
    "\n",
    "    df_final_vpf_all = pd.DataFrame({\n",
    "        'idx': np.array(models),\n",
    "        f'mean_abs_value_{len_df_pred//24}': np.around(df_pred_mean.loc[models, 'd2_mean_abs_error'].dropna(), 4),\n",
    "        f'mean_relative_value_{len_df_pred//24}': np.around(df_pred_mean.loc[models, 'd2_mean_relative_error'].dropna(), 4),\n",
    "\n",
    "        'median_abs_value': np.around(df_pred_median.loc[models, 'd2_mean_abs_error'].dropna(), 4),\n",
    "        'median_relative_value': np.around(df_pred_median.loc[models, 'd2_mean_relative_error'].dropna(), 4),\n",
    "\n",
    "        'q25_abs_value': np.around(df_pred_q25.loc[models, 'd2_mean_abs_error'].dropna(), 4),\n",
    "        'q25_relative_value': np.around(df_pred_q25.loc[models, 'd2_mean_relative_error'].dropna(), 4),\n",
    "\n",
    "        'q75_abs_value': np.around(df_pred_q75.loc[models, 'd2_mean_abs_error'].dropna(), 4),\n",
    "        'q75_relative_value': np.around(df_pred_q75.loc[models, 'd2_mean_relative_error'].dropna(), 4),\n",
    "\n",
    "        'exp_model': exp_model,\n",
    "        'n_models_per_day': n_models_per_day,\n",
    "        'model_hyperparameters': model_hyperparameters,\n",
    "        'train_start/duration': train_start_or_duration,\n",
    "        'train_features': train_features,\n",
    "        'exp_uuid': exp_uuid,\n",
    "    })\n",
    "\n",
    "    df_final_vpf_all = df_final_vpf_all.set_index('idx')\n",
    "    df_final_vpf_all.to_csv(os.path.join(os.getcwd(), f'/datalake/mhp/{location}/gr/{brigade}/ecf/statistical_result', \n",
    "            f'(all_models)_statistical_result_{location}_{brigade}_{datetime.now().strftime(\"%Y%m%d\")}.csv'))\n",
    "\n",
    "    return df_final_vpf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e1aaab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "location = 'vpf'\n",
    "brigades_list = ['brigade_13', 'brigade_14', 'brigade_49']\n",
    "# brigades_list = ['brigade_1', 'brigade_2', 'brigade_3', 'brigade_4', 'brigade_5', 'brigade_6', \n",
    "#                 'brigade_7', 'brigade_8', 'brigade_9', 'brigade_10', 'brigade_11', 'brigade_12', \n",
    "#                 'brigade_13', 'brigade_14', 'brigade_22', 'brigade_42', 'brigade_43', 'brigade_47', 'brigade_49']\n",
    "models_list = ['random_forest', 'xgboost']\n",
    "sum_brigades_statistics_uuid = str(uuid.uuid1())\n",
    "\n",
    "\n",
    "df_pred_median = pd.DataFrame()\n",
    "df_pred_mean = pd.DataFrame()\n",
    "df_pred_q25 = pd.DataFrame()\n",
    "df_pred_q75 = pd.DataFrame()\n",
    "\n",
    "    \n",
    "if location == 'vpf':\n",
    "    for brigade in brigades_list:\n",
    "        print(brigade)\n",
    "        file_paths_to_prediction, file_paths_to_info, yaml_file_paths, model_parameters, experiment_names = get_paths(location, models_list,  brigade)\n",
    "        \n",
    "        df_preds, len_df_pred = calculate_pred_cons(location, brigade, file_paths_to_prediction, experiment_names)\n",
    "        df_real_consumption = calculate_real_cons_df(location, brigade, df_preds, len_df_pred)\n",
    "        for exp_num, exp_name in enumerate(experiment_names):\n",
    "            df_pred_consumption = form_pred_consumption_df(df_preds, len_df_pred, exp_name)\n",
    "            df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75 = get_errors_dataframe(exp_num, df_pred_consumption, df_real_consumption, df_pred_median, df_pred_mean, df_pred_q25, df_pred_q75, file_paths_to_info, model_parameters, exp_name)\n",
    "\n",
    "        df_pred_median = df_pred_median.set_index('idx')\n",
    "        df_pred_mean = df_pred_mean.set_index('idx')\n",
    "        df_pred_q25 = df_pred_q25.set_index('idx')\n",
    "        df_pred_q75 = df_pred_q75.set_index('idx')\n",
    "            \n",
    "        \n",
    "        df_final_best_vpf_by_day = final_df_vpf_best_exp_by_day(location, brigade, models_list, df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75, model_parameters, sum_brigades_statistics_uuid)\n",
    "        df_final_vpf_all = final_df_vpf_all_exp_by_day(location, brigade, df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75, model_parameters)\n",
    "\n",
    "        \n",
    "elif location == 'mpf':\n",
    "    model_parameters, file_paths = get_paths(location, models_list, brigade=None)\n",
    "    df_pred_mean, df_pred_median, df_pred_q25, df_pred_q75, len_df_pred = get_dataframes(file_paths)\n",
    "        \n",
    "    df_final = final_df_mpf(location, df_pred_mean, df_pred_median, df_pred_q75, df_orig_mean, df_orig_median, df_orig_q75, len_df_pred, len_df_orig, model_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
