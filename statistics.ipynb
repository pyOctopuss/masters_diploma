{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71220b6-2359-42b1-bc2f-83dd44049cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406b1fd0-b5b5-4083-af14-14f04d5192bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7437fae-d5e5-4c67-970f-290bf52c30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd6753e-971e-4b12-aabe-16d078990d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(models_list):\n",
    "    '''\n",
    "    Finds all the paths to forecasts and experiments metadata (directories /forecast/ and /wf_result/)\n",
    "    \n",
    "    Returns list with paths to forecast files, dict with metadata and list of all the experiment names\n",
    "    '''\n",
    "    \n",
    "    uuids = []\n",
    "    model_names = []\n",
    "    train_start_or_duration = []\n",
    "    hyperparameters = []\n",
    "    features = []\n",
    "    n_models = []\n",
    "    \n",
    "    paths_to_predictions = []\n",
    "    paths_to_info = []\n",
    "\n",
    "    forecast_paths = []\n",
    "    metadata_paths = []\n",
    "\n",
    "\n",
    "    for model in models_list:\n",
    "        paths_to_predictions += glob(f'/masters_diploma/forecast/{model}/research_task_*/{model}_*/')\n",
    "        paths_to_info += glob(f'/masters_diploma/wf_result/{model}/research_task_*')\n",
    "\n",
    "#     print(len(paths_to_predictions))\n",
    "#     print(len(paths_to_info))\n",
    "            \n",
    "    for path2 in paths_to_info:   \n",
    "#     for path2 in [max(paths_to_info, key=os.path.getctime)]:   # тільки для останнього експерименту\n",
    "        metadata_paths.extend(glob(os.path.join(path2, '*.csv')))\n",
    "\n",
    "\n",
    "    for path2 in paths_to_predictions:\n",
    "#     for path2 in [max(paths_to_predictions, key=os.path.getctime)]:   # тільки для останнього експерименту\n",
    "        prediction_paths = glob(os.path.join(path2, f'*.csv'))\n",
    "        if len(prediction_paths) > 0:\n",
    "            forecast_paths.append(prediction_paths)\n",
    "\n",
    "    yaml_file_paths = [f.replace('.csv', '.yaml') for f in metadata_paths]\n",
    "\n",
    "    metadata = {}\n",
    "    experiment_names = []\n",
    "    for file in yaml_file_paths: \n",
    "        with open(file, 'r') as f:\n",
    "            res = yaml.safe_load(f)\n",
    "\n",
    "        shorten_uuid = \"-\".join([res['unique_uuid'].split('-')[0], res['unique_uuid'].split('-')[-2]])\n",
    "        dur = res['duration_training_history'] if 'duration_training_history' in res else res['train_start']\n",
    "\n",
    "        metadata[shorten_uuid] = {\n",
    "            \"uuid\": res['unique_uuid'],\n",
    "            \"model_name\": res['model_name'],\n",
    "            \"duration/train_start\": dur,\n",
    "            \"hyperparameters\": res['model_hyperparameters'],\n",
    "            \"features\": res['train_features']\n",
    "        }\n",
    "\n",
    "        experiment_names.append(f\"{res['model_name']}_{shorten_uuid}\")   \n",
    "    \n",
    "\n",
    "    return forecast_paths, metadata_paths, metadata, experiment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2dc372-5f6a-4b19-8699-e1fcac7205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facts(path_to_all):\n",
    "\n",
    "    dateparse = lambda dates: datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "    path_to_weather = f'{path_to_all}/processed_data/history_weather.csv'\n",
    "\n",
    "    fact_temperature = pd.read_csv(\n",
    "        path_to_weather,\n",
    "        parse_dates=['date'],\n",
    "        index_col='date', \n",
    "        date_parser=dateparse\n",
    "    )[['temperature']]\n",
    "    \n",
    "    fact_temperature.index.name = 'date_time'\n",
    "\n",
    "    return fact_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f16cdbd-7811-4c0a-b0b7-cc722f432396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecasts_df(fact_pred, paths_to_exp_forecasts, exp_name):\n",
    "\n",
    "    '''\n",
    "    Creating a dataframe of forecasted temperature values\n",
    "    '''\n",
    "\n",
    "    dateparse = lambda dates: datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df = fact_pred.copy()\n",
    "    \n",
    "    for num_exp, day_pred in enumerate(paths_to_exp_forecasts):\n",
    "        d = day_pred.split('_')[-4]\n",
    "        day_date = day_pred.split('\\\\')[-1].split('_')[-1].split(')')[0].split('(')[1]\n",
    "#         print(day_date)\n",
    "\n",
    "        pred = pd.read_csv(\n",
    "            day_pred,\n",
    "            parse_dates=['date_time'],\n",
    "            index_col='date_time', \n",
    "            date_parser=dateparse\n",
    "        )\n",
    "        \n",
    "        for h in range(24):\n",
    "            try:\n",
    "\n",
    "                df.loc[pd.to_datetime(day_date) + timedelta(hours=h), f'{exp_name}_{d}'] = pred.loc[pd.to_datetime(day_date) + timedelta(hours=h),'0']\n",
    "            \n",
    "            except KeyError as e:\n",
    "                \n",
    "                print(day_pred)\n",
    "                continue\n",
    "                \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68af895-e71f-4eb1-b253-5fe0a9f8558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat(fact_pred, info, day, path_to_files):\n",
    "    \n",
    "    forecast_cols = [col for col in fact_pred.columns if day in col]\n",
    "    df = fact_pred[['temperature'] + forecast_cols].dropna()\n",
    "    \n",
    "    df.columns = df.columns.str.replace(r'_d-\\d+$', '', regex=True)\n",
    "\n",
    "    \n",
    "    absolute_errors = df[df.columns[1:]].sub(df['temperature'], axis=0)\n",
    "    \n",
    "    relative_errors = absolute_errors.div(df['temperature'], axis=0)\n",
    "    \n",
    "    print(absolute_errors.columns)\n",
    "    \n",
    "    stat_dict = {}\n",
    "    for exp in info.keys():\n",
    "        exp_name = f\"{info[exp]['model_name']}_{exp}\"\n",
    "        \n",
    "        stat_dict[exp] = {\n",
    "            'mean_abs_value': absolute_errors[exp_name].abs().mean(),\n",
    "            'mean_rel_value': relative_errors[exp_name].abs().mean(),\n",
    "            'median_abs_value': absolute_errors[exp_name].abs().median(),\n",
    "            'median_rel_value': relative_errors[exp_name].abs().median(),\n",
    "            'q25_abs_value': absolute_errors[exp_name].abs().quantile(0.25),\n",
    "            'q25_rel_value': relative_errors[exp_name].abs().quantile(0.25),\n",
    "            'q75_abs_value': absolute_errors[exp_name].abs().quantile(0.75),\n",
    "            'q75_rel_value': relative_errors[exp_name].abs().quantile(0.75),\n",
    "            \"model_name\": info[exp][\"model_name\"],\n",
    "            \"hyperparameters\": info[exp][\"hyperparameters\"],\n",
    "            \"features\": info[exp][\"features\"],\n",
    "            \"train_start\": info[exp][\"duration/train_start\"]\n",
    "        }\n",
    "        \n",
    "    stat = pd.DataFrame(stat_dict).T\n",
    "        \n",
    "    stat_per_h = pd.DataFrame(relative_errors.abs().groupby(df.index.hour).median(), columns=relative_errors.columns)\n",
    "    \n",
    "    \n",
    "    path = os.path.join(path_to_files, 'statistics', f'general_statistics_{day}.xlsx')\n",
    "    path_h = os.path.join(path_to_files, 'statistics', f'general_statistics_{day}_by_hour.xlsx')\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "    \n",
    "        gen_stat_df = pd.read_excel(path)\n",
    "        gen_stat_h_df = pd.read_excel(path_h)\n",
    "        gen_stat_df = pd.concat([gen_stat_df, stat]).drop_duplicates()\n",
    "        gen_stat_h_df = pd.concat([gen_stat_h_df, stat_per_h]).drop_duplicates()\n",
    "\n",
    "        gen_stat_df.to_excel(path, index=False)\n",
    "        gen_stat_h_df.to_excel(path_h, index=False)\n",
    "        \n",
    "    else:\n",
    "        stat.to_excel(path, index=False)\n",
    "        stat_per_h.to_excel(path_h)\n",
    "    \n",
    "    return stat, stat_per_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a57871b-fc15-4ecd-9a6f-0e0c41ee595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models_per_hour(stat_per_h, day, info, path_to_files):\n",
    "    \n",
    "    min_errors = stat_per_h_df.min(axis=1)\n",
    "    best_exps = stat_per_h_df.idxmin(axis=1)\n",
    "    \n",
    "    \n",
    "    best_models = pd.concat([best_exps, min_errors], axis=1)\n",
    "    best_models.columns=['experiment_name', 'median_rel_err_value']\n",
    "    \n",
    "    for h in best_models.index:\n",
    "        exp = best_models.loc[h, 'experiment_name']\n",
    "        meta = info[exp]\n",
    "        \n",
    "        best_models.loc[best_models['experiment_name']==exp, 'model_name'] = meta['model_name']\n",
    "        best_models.loc[best_models['experiment_name']==exp, 'hyperparameters'] = meta['hyperparameters']\n",
    "        best_models.loc[best_models['experiment_name']==exp, 'features'] = meta['features']\n",
    "        best_models.loc[best_models['experiment_name']==exp, 'duration/train_start'] = meta['duration/train_start']\n",
    "        \n",
    "        \n",
    "    path = get_next_versioned_filename(os.path.join(path_to_files, 'statistics', 'best_for_hour'), day)\n",
    "    best_models.to_excel(path)\n",
    "    \n",
    "    \n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f160e60c-345b-44f6-ab4b-984406581156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_versioned_filename(base_dir, day, prefix=\"hourly_best\", ext=\".xlsx\"):\n",
    "    today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    pattern = re.compile(rf\"{prefix}_{day}_{today}_v(\\d+){re.escape(ext)}\")\n",
    "    \n",
    "    # Отримаємо всі файли в директорії, які відповідають шаблону\n",
    "    existing_versions = []\n",
    "    for filename in os.listdir(base_dir):\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            existing_versions.append(int(match.group(1)))\n",
    "    \n",
    "    next_version = max(existing_versions, default=0) + 1\n",
    "    new_filename = f\"{prefix}_{today}_v{next_version}{ext}\"\n",
    "    \n",
    "    \n",
    "    return os.path.join(base_dir, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64089035-6622-47fa-8767-d6f85819ca59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathering experiment info...\n",
      "loading fact temperature dataset...\n",
      "adding experiments` forecasts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 164/164 [02:08<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "calculating statistics for day 0...\n",
      "Index(['xgboost_430dfb8f-a2d2', 'xgboost_430dfb90-afb0',\n",
      "       'xgboost_430dfb91-8c7d', 'xgboost_430dfb92-afe1',\n",
      "       'xgboost_430dfb93-9937', 'xgboost_430dfb94-bc1a',\n",
      "       'xgboost_430dfb95-bcb1', 'xgboost_430dfb96-9f74',\n",
      "       'xgboost_430dfb97-a74a', 'xgboost_430dfb98-9194',\n",
      "       'xgboost_430dfb99-aade', 'xgboost_430dfb9a-9978',\n",
      "       'xgboost_430dfb9b-8c23', 'xgboost_430dfb9c-b9a9',\n",
      "       'xgboost_430dfb9d-a005', 'xgboost_430dfb9e-88ad',\n",
      "       'xgboost_430dfb9f-82fb', 'xgboost_430dfba0-b867',\n",
      "       'xgboost_430dfba1-b784', 'xgboost_430dfba2-938a',\n",
      "       'xgboost_430dfba3-9c9c', 'xgboost_430dfba4-a408',\n",
      "       'xgboost_430dfba5-9fd9', 'xgboost_430dfba6-950a',\n",
      "       'xgboost_430dfba7-b07c', 'xgboost_430dfba8-9e68',\n",
      "       'xgboost_430dfba9-822f', 'xgboost_430dfbaa-aecb',\n",
      "       'xgboost_430dfbab-be7a', 'xgboost_430dfbac-93a3',\n",
      "       'xgboost_430dfbe1-ac10', 'xgboost_430dfbe2-80eb',\n",
      "       'xgboost_430dfbe3-8e5d', 'xgboost_430dfbe4-85c4',\n",
      "       'xgboost_430dfbe5-8f5f', 'xgboost_430dfbe6-96a6',\n",
      "       'xgboost_430dfbe7-8740', 'xgboost_430dfbe8-80ec',\n",
      "       'xgboost_430dfbe9-ad1a', 'xgboost_430dfbea-98a9',\n",
      "       'xgboost_430dfbeb-9bf4', 'xgboost_430dfbec-9f6d',\n",
      "       'xgboost_430dfbed-8b55', 'xgboost_430dfbee-ab59',\n",
      "       'xgboost_430dfbef-ba01', 'xgboost_430dfbf0-8f67',\n",
      "       'xgboost_430dfbf1-a915', 'xgboost_430dfbf2-b0a1',\n",
      "       'xgboost_430dfbf3-8185', 'xgboost_430dfbf4-a209',\n",
      "       'xgboost_430dfbf5-a854', 'xgboost_430dfbf6-873a',\n",
      "       'xgboost_430dfbf7-94fd', 'xgboost_430dfbf8-b899',\n",
      "       'xgboost_430dfbf9-af03', 'xgboost_430dfbfa-97d5',\n",
      "       'xgboost_430dfbfb-be9f', 'xgboost_430dfbfc-b1f8',\n",
      "       'xgboost_430dfbfd-9329', 'xgboost_430dfbfe-8a90',\n",
      "       'lightgbm_430dfbad-8ad8', 'lightgbm_430dfbae-9ee1',\n",
      "       'lightgbm_430dfbaf-9025', 'lightgbm_430dfbb0-9c5b',\n",
      "       'lightgbm_430dfbb1-862e', 'lightgbm_430dfbb2-9587',\n",
      "       'lightgbm_430dfbb3-a8ac', 'lightgbm_430dfbb4-89cf',\n",
      "       'lightgbm_430dfbb5-ac5e', 'lightgbm_430dfbb6-a83e',\n",
      "       'lightgbm_430dfbb7-8661', 'lightgbm_430dfbb8-80c1',\n",
      "       'lightgbm_430dfbff-8c65', 'lightgbm_430dfc00-b77c',\n",
      "       'lightgbm_430dfc01-becc', 'lightgbm_430dfc02-a822',\n",
      "       'lightgbm_430dfc03-931f', 'lightgbm_430dfc04-8666',\n",
      "       'lightgbm_430dfc05-a5bb', 'lightgbm_430dfc06-9a61',\n",
      "       'lightgbm_430dfc07-977c', 'lightgbm_430dfc08-a22e',\n",
      "       'lightgbm_430dfc09-98ec', 'lightgbm_430dfc0a-9a63'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'random_forest_430dfbb9-a577'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'random_forest_430dfbb9-a577'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcalculating statistics for day \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m     stat, stat_per_h \u001b[38;5;241m=\u001b[39m \u001b[43mget_stat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfact_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43md\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_to_all\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinished\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinding best model for hour...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m, in \u001b[0;36mget_stat\u001b[1;34m(fact_pred, info, day, path_to_files)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     17\u001b[0m     exp_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo[exp][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m     stat_dict[exp] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 20\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_abs_value\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mabsolute_errors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_rel_value\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean(),\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_abs_value\u001b[39m\u001b[38;5;124m'\u001b[39m: absolute_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmedian(),\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian_rel_value\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmedian(),\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq25_abs_value\u001b[39m\u001b[38;5;124m'\u001b[39m: absolute_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m),\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq25_rel_value\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m),\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq75_abs_value\u001b[39m\u001b[38;5;124m'\u001b[39m: absolute_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m),\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq75_rel_value\u001b[39m\u001b[38;5;124m'\u001b[39m: relative_errors[exp_name]\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m),\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: info[exp][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: info[exp][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperparameters\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: info[exp][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_start\u001b[39m\u001b[38;5;124m\"\u001b[39m: info[exp][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration/train_start\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     32\u001b[0m     }\n\u001b[0;32m     34\u001b[0m stat \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(stat_dict)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     36\u001b[0m stat_per_h \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(relative_errors\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mgroupby(df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mhour)\u001b[38;5;241m.\u001b[39mmedian(), columns\u001b[38;5;241m=\u001b[39mrelative_errors\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'random_forest_430dfbb9-a577'"
     ]
    }
   ],
   "source": [
    "path_to_all = '/masters_diploma/'\n",
    "models_list = ['xgboost', 'random_forest', 'lightgbm']\n",
    "\n",
    "print('gathering experiment info...')\n",
    "paths, metadata_paths, metadata_dict, exp_names = get_paths(models_list)\n",
    "\n",
    "print('loading fact temperature dataset...')\n",
    "fact_temperature = facts(path_to_all)\n",
    "fact_pred = fact_temperature.copy()\n",
    "\n",
    "print('adding experiments` forecasts...')\n",
    "\n",
    "for key, metadata in tqdm(metadata_dict.items()):\n",
    "#     print(key, metadata)\n",
    "    \n",
    "    exp_name = f\"{metadata['model_name']}_{key}\"\n",
    "    \n",
    "    for exp_forecasts in paths:\n",
    "        \n",
    "        k = exp_forecasts[0].split(\"\\\\\")[-2].split('-')\n",
    "        exp = \"-\".join([k[0], k[-2]])\n",
    "        \n",
    "        if exp == exp_name:\n",
    "\n",
    "            fact_pred = make_forecasts_df(fact_pred, exp_forecasts, exp)\n",
    "#             print(len(fact_pred.columns))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "fact_pred = fact_pred.loc['2025-01-01':'2025-01-08']\n",
    "\n",
    "for d in range(4):\n",
    "    print(f'\\ncalculating statistics for day {d}...')\n",
    "    stat, stat_per_h = get_stat(fact_pred, metadata_dict, f'd-{d}', path_to_all)\n",
    "    print('finished')\n",
    "    print('finding best model for hour...')\n",
    "    best_models_df = get_best_models_per_hour(stat_per_h, f'd-{d}', metadata_dict)\n",
    "    print('done\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73889811-1303-413c-b4b7-b87f7f2f6d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6903ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
