{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2ccc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c82aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c158484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e839b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(models_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds all the paths to forecasts and experiments metadata (directories /forecast/ and /wf_result/)\n",
    "\n",
    "    Returns:\n",
    "        forecast_paths   : list[str]  - шляхи до всіх CSV з прогнозами (останній research_task_* для кожної моделі)\n",
    "        metadata_paths   : list[str]  - шляхи до всіх CSV з метаданими (останній research_task_* для кожної моделі)\n",
    "        metadata         : dict       - словник, зчитаний з відповідних YAML файлів (за іменами CSV -> .yaml)\n",
    "        experiment_names : list[str]  - [f\"{model_name}_{short_uuid}\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    base_forecast = Path(\"/masters_diploma/forecast\")\n",
    "    base_info     = Path(\"/masters_diploma/wf_result\")\n",
    "\n",
    "    forecast_paths = []\n",
    "    metadata_paths = []\n",
    "    metadata = {}\n",
    "    experiment_names = []\n",
    "\n",
    "    def latest_task_dir(root: Path) -> Path | None:\n",
    "        candidates = list(root.glob(\"research_task_*\"))\n",
    "        if not candidates:\n",
    "            return None\n",
    "        return max(candidates, key=lambda p: p.stat().st_ctime)\n",
    "\n",
    "    for model in models_list:\n",
    "        info_root = base_info / model\n",
    "        info_task = latest_task_dir(info_root)\n",
    "        if info_task and info_task.is_dir():\n",
    "            mp = sorted([str(p) for p in info_task.glob(\"*.csv\")])\n",
    "            metadata_paths.extend(mp)\n",
    "            \n",
    "        pred_root = base_forecast / model\n",
    "        pred_task = latest_task_dir(pred_root)\n",
    "        if pred_task and pred_task.is_dir():\n",
    "            fps = sorted([str(p) for p in pred_task.rglob(\"*.csv\")])\n",
    "            forecast_paths.extend(fps)\n",
    "\n",
    "            \n",
    "    yaml_file_paths = []\n",
    "    for csv_path in metadata_paths:\n",
    "        y = Path(csv_path).with_suffix(\".yaml\")\n",
    "        if y.exists():\n",
    "            yaml_file_paths.append(str(y))\n",
    "\n",
    "    for file in yaml_file_paths:\n",
    "        try:\n",
    "            yaml.SafeLoader.add_constructor(\n",
    "                'tag:yaml.org,2002:python/tuple',\n",
    "                lambda loader, node: tuple(loader.construct_sequence(node))\n",
    "            )\n",
    "\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                res = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        uid = res.get(\"unique_uuid\", \"\")\n",
    "        parts = uid.split(\"-\")\n",
    "        if len(parts) >= 2:\n",
    "            shorten_uuid = \"-\".join([parts[0], parts[-2]])\n",
    "        else:\n",
    "            shorten_uuid = uid or \"unknown\"\n",
    "\n",
    "        dur = res.get(\"duration_training_history\", res.get(\"train_start\"))\n",
    "        hp = (res.get(\"model_hyperparameters\"), res.get(\"fit_kwargs\")) if res.get(\"model_name\") == 'sarimax' else res.get(\"model_hyperparameters\")\n",
    "        \n",
    "\n",
    "        metadata[shorten_uuid] = {\n",
    "            \"uuid\": uid,\n",
    "            \"model_name\": res.get(\"model_name\"),\n",
    "            \"duration/train_start\": dur,\n",
    "            \"hyperparameters\": hp,\n",
    "            \"features\": res.get(\"train_features\"),\n",
    "        }\n",
    "\n",
    "        experiment_names.append(f\"{res.get('model_name')}_{shorten_uuid}\")\n",
    "\n",
    "        \n",
    "    return forecast_paths, metadata_paths, metadata, experiment_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdb908eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facts(path_to_all):\n",
    "\n",
    "    dateparse = lambda dates: datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "    path_to_weather = f'{path_to_all}/processed_data/history_weather.csv'\n",
    "\n",
    "    fact_temperature = pd.read_csv(\n",
    "        path_to_weather,\n",
    "        parse_dates=['date'],\n",
    "        index_col='date', \n",
    "        date_parser=dateparse\n",
    "    )[['temperature']]\n",
    "    \n",
    "    fact_temperature.index.name = 'date_time'\n",
    "\n",
    "    return fact_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9122cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecasts_df(fact_pred, paths_to_exp_forecasts, exp_name):\n",
    "\n",
    "    '''\n",
    "    Creating a dataframe of forecasted temperature values\n",
    "    '''\n",
    "\n",
    "    dateparse = lambda dates: datetime.strptime(dates, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    df = fact_pred.copy()\n",
    "    \n",
    "    for num_exp, day_pred in enumerate([paths_to_exp_forecasts]):\n",
    "        _ = day_pred.split('_')\n",
    "        if \"_\".join([_[-4], _[-3]]) == 'random_forest':\n",
    "            d = _[-5]\n",
    "        else:\n",
    "            d = _[-4]\n",
    "            \n",
    "        day_date = day_pred.split('\\\\')[-1].split('_')[-1].split(')')[0].split('(')[1]\n",
    "#         print(day_date)\n",
    "\n",
    "        pred = pd.read_csv(\n",
    "            day_pred,\n",
    "            parse_dates=['date_time'],\n",
    "            index_col='date_time', \n",
    "            date_parser=dateparse\n",
    "        )\n",
    "        \n",
    "        for h in range(24):\n",
    "            try:\n",
    "                col_name = pred.columns[0]\n",
    "                df.loc[pd.to_datetime(day_date) + timedelta(hours=h), f'{exp_name}_{d}'] = pred.loc[pd.to_datetime(day_date) + timedelta(hours=h),col_name]\n",
    "            \n",
    "            except KeyError as e:\n",
    "                \n",
    "                print(day_pred)\n",
    "                continue\n",
    "                \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26918c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gathering experiment info...\n",
      "loading fact temperature dataset...\n",
      "adding experiments` forecasts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████████████████████████████████████▎    | 18402/19650 [1:59:24<08:05,  2.57it/s]\n"
     ]
    }
   ],
   "source": [
    "path_to_all = '/masters_diploma/'\n",
    "models_list = ['random_forest', 'xgboost', 'lightgbm', 'sarimax']\n",
    "\n",
    "print('gathering experiment info...')\n",
    "paths, metadata_paths, metadata_dict, exp_names = get_paths(models_list)\n",
    "\n",
    "print('loading fact temperature dataset...')\n",
    "fact_temperature = facts(path_to_all)\n",
    "fact_pred = fact_temperature.copy()\n",
    "\n",
    "print('adding experiments` forecasts...')\n",
    "\n",
    "\n",
    "for exp_forecasts in tqdm(paths):\n",
    "      \n",
    "    k = exp_forecasts.split(\"\\\\\")[-2].split('-')\n",
    "#     k = exp_forecasts[0].split(\"\\\\\")[-2].split('-')\n",
    "    exp = \"-\".join([k[0], k[-2]])\n",
    "    \n",
    "    fact_pred = make_forecasts_df(fact_pred, exp_forecasts, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939dfd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\n",
    "#     \"#4169E1\", \"#DC143C\", \"#228B22\", \"#DAA520\", \"#FF8C00\", \"#8A2BE2\", \"#00BFFF\", \"#FF1493\"\n",
    "# ]\n",
    "\n",
    "# for feature in list(features.keys()):\n",
    "    \n",
    "#     fig = make_subplots(rows=1, cols=1, \n",
    "#                     subplot_titles=(f\"Means of {feature.title()}\"))\n",
    "\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         y=df.loc['2024-01-01':, feature],\n",
    "#         x=df.loc['2024-01-01':,:].index,\n",
    "#         name=feature,\n",
    "#         marker_color=\"black\"\n",
    "#     ), row=1, col=1)\n",
    "    \n",
    "#     for i, name in enumerate([i for i in df.columns if i.startswith(f\"{feature}_mean_\")]):\n",
    "\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             y=df.loc['2024-01-01':, name],\n",
    "#             x=df.loc['2024-01-01':,:].index,\n",
    "#             name=name,\n",
    "#             marker_color=colors[i]\n",
    "#         ), row=1, col=1)\n",
    "\n",
    "#     fig.update_layout(\n",
    "#         title=f'Means of {feature.title()}', \n",
    "#         xaxis_tickangle=-45,\n",
    "#         width=1300, height=1000,\n",
    "#         hovermode=\"x\"\n",
    "#     )\n",
    "\n",
    "#     fig.write_html(f'/masters_diploma/correlation_vizualizations/visualization_mean_{feature}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
