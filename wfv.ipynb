{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc5c74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d57b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import re\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "from yaml import dump\n",
    "import uuid\n",
    "import itertools\n",
    "from shutil import copy2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194a5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6627bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2392ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c4f54",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5172d8a5",
   "metadata": {},
   "source": [
    "#### initialize all required valiables, prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042f2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "\n",
    "    train_end = datetime(2025, 8, 31, 23)\n",
    "    test_start = datetime(2025, 9, 1, 0)\n",
    "    test_end = datetime(2025, 9, 14, 23)\n",
    "    \n",
    "    train_features_set = [\n",
    "        ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks',\n",
    "         'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'],\n",
    "        ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks',\n",
    "        'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'],\n",
    "        ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks']\n",
    "    ]\n",
    "\n",
    "    \n",
    "    date_parse = lambda dates: pd.to_datetime(dates)\n",
    "    path = f\"/masters_diploma/processed_data/history_weather.csv\"\n",
    "    \n",
    "    full_set = pd.read_csv(\n",
    "        path,\n",
    "        parse_dates=[\"date\"],\n",
    "        date_parser=date_parse,\n",
    "        index_col=[\"date\"],\n",
    "    )\n",
    "    \n",
    "\n",
    "    full_set = full_set[:test_end].fillna(0)\n",
    "#     full_set = future_target(full_set, test_start, test_end)\n",
    "    \n",
    "    \n",
    "#     test_start = datetime(full_set.loc[test_start:].index[0].year, full_set.loc[test_start:].index[0].month, full_set.loc[test_start:].index[0].day)\n",
    "#     train_end = datetime(full_set.loc[:train_end].index[-1].year, full_set.loc[:train_end].index[-1].month, full_set.loc[:train_end].index[-1].day)\n",
    "    \n",
    "    \n",
    "    return full_set, train_end, test_start, test_end, train_features_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e12930c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def future_target(df, date_start, date_end):\n",
    "    \n",
    "    date_range = pd.date_range(date_start, date_end, freq='H')\n",
    "    \n",
    "    add_df = pd.DataFrame(index=date_range, columns=df.columns)\n",
    "    \n",
    "#     add_df\n",
    "    \n",
    "    df = pd.concat([df, add_df])\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42b5f2c",
   "metadata": {
    "code_folding": [
     0,
     18,
     43,
     66
    ]
   },
   "outputs": [],
   "source": [
    "def models_hyperparameter_random_forest():\n",
    "\n",
    "    depth_list = [4, 5, 6, 7]\n",
    "    n_estimators_list = [50, 100, 200, 500, 1000]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                        'n_estimators': n_estimators,\n",
    "                        'n_jobs': -1,\n",
    "                        'random_state': 2,\n",
    "                        'max_depth': depth,\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_xgboost():\n",
    "\n",
    "    depth_list = [5, 7, 9]\n",
    "    n_estimators_list = [50, 100, 200, 500, 1000]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'n_jobs': -1,\n",
    "                    'max_depth': depth,\n",
    "                    'eta': 0.3,\n",
    "                    'booster': 'gbtree',\n",
    "                    'objective': 'reg:squarederror',\n",
    "                    'eval_metric': 'rmse',\n",
    "                    'subsample': 1,\n",
    "                    'colsample_bytree': 1,\n",
    "                    'min_child_weight': 1,\n",
    "                    'random_state': 2,\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_lgbm():\n",
    "\n",
    "    \n",
    "    depth_list = [6, 7]\n",
    "    n_estimators_list = [10, 50, 100]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for depth, n_estimators in itertools.product(depth_list, n_estimators_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                    'n_estimators': n_estimators,\n",
    "                    'n_jobs': -1,\n",
    "                    'max_depth': depth,\n",
    "                    'eta': 0.3,\n",
    "                    'random_state': 2,\n",
    "                    'objective': 'binary',\n",
    "                    'verbosity': -1,\n",
    "                    'metric': 'binary', \n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model\n",
    "\n",
    "\n",
    "def models_hyperparameter_prophet():\n",
    "    \n",
    "    hyperparameters_for_model.append({})\n",
    "\n",
    "    seasonality_list = [\"seasonality_yearly\", \"seasonality_daily\"]\n",
    "    season_list = [\"additive\", \"multiplicative\"]\n",
    "    \n",
    "    hyperparameters_for_model = []\n",
    "    \n",
    "    for seasonality, season in itertools.product(seasonality_list, season_list):\n",
    "        hyperparameters_for_model.append({\n",
    "                        'growth': \"logistic\",\n",
    "                        'season': season,\n",
    "                        f'{seasonality}': True,\n",
    "            })\n",
    "\n",
    "    return hyperparameters_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01393351",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def define_parameters(train_end, test_start, test_end, train_features_set, forecast_steps, models_dict):\n",
    "    \n",
    "    list_of_configs = []\n",
    "    \n",
    "    model = None\n",
    "    \n",
    "#     for duration in [90, 240]:\n",
    "    for train_start in [datetime(2020, 1, 1), datetime(2024, 1, 1), datetime(2023, 9, 1)]:\n",
    "        for md in models_dict.values():\n",
    "            if md == 'random_forest':\n",
    "                hyperparameters_for_model = models_hyperparameter_random_forest()\n",
    "            elif md == 'xgboost':\n",
    "                hyperparameters_for_model = models_hyperparameter_xgboost()\n",
    "            elif md == 'lightgbm':\n",
    "                hyperparameters_for_model = models_hyperparameter_lgbm()\n",
    "            elif md == 'prophet':\n",
    "                hyperparameters_for_model = models_hyperparameter_prophet()\n",
    "            else:\n",
    "                print('Unknown model')\n",
    "                return\n",
    "\n",
    "\n",
    "            for hp in hyperparameters_for_model:\n",
    "\n",
    "                if md == 'random_forest':\n",
    "                    model = RandomForestRegressor(**hp)\n",
    "                elif md == 'xgboost':\n",
    "                    model = XGBRegressor(**hp)\n",
    "                elif md == 'lightgbm':\n",
    "                    model = LGBMRegressor(**hp)\n",
    "                elif md == 'prophet':\n",
    "                    model = Prophet()\n",
    "    #                 model = Prophet(**hp)\n",
    "                else:\n",
    "                    print('Unknown model')\n",
    "\n",
    "                for train_features in train_features_set:\n",
    "                    config = {\n",
    "                        'unique_uuid': str(uuid.uuid1()),\n",
    "                        'train_start': train_start,\n",
    "                        'train_end': train_end,\n",
    "                        'test_start': test_start,\n",
    "                        'test_end': test_end,\n",
    "    #                     'duration_training_history': duration,\n",
    "                        'target_column': 'temperature',\n",
    "                        'train_features': train_features,\n",
    "                        'path_to_result': f'/masters_diploma/',\n",
    "                        'forecast_days': forecast_steps,\n",
    "        #                 'hour_mean_value': 5,\n",
    "                        'model_name': md,\n",
    "                        'model': model,\n",
    "                        'model_hyperparameters': hp,\n",
    "                    }\n",
    "\n",
    "                    list_of_configs.append(config.copy())\n",
    "    \n",
    "    return list_of_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de80c2e",
   "metadata": {},
   "source": [
    "#### functions used in wfv service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4016f075",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def data(day, X_full_set, y_full_set, train_start, config, forecast_steps):\n",
    "\n",
    "    X_train = X_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    X_test = X_full_set.loc[config[\"test_start\"]+timedelta(days=day): config[\"test_start\"]+timedelta(days=day+forecast_steps, hours=23)]\n",
    "    \n",
    "    y_train = y_full_set.loc[train_start:config[\"train_end\"]]\n",
    "    y_test = y_full_set.loc[config[\"test_start\"]+timedelta(days=day): config[\"test_start\"]+timedelta(days=day+forecast_steps, hours=23)]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1c8fa3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def standardize_mean_values(day, df_test, df_train, full_set, config):\n",
    "    \n",
    "    agg_cols = [col for col in config['train_features'] if (col.startswith(f\"{config['target_column']}_m\")) & (col.endswith('days'))]\n",
    "\n",
    "    if agg_cols:\n",
    "        for agg in agg_cols:\n",
    "            if agg in df_test.columns:\n",
    "                try:\n",
    "#                 print(config[\"test_start\"]+timedelta(days=day), df_test.loc[config[\"test_start\"]+timedelta(days=day), agg])\n",
    "                    num = df_test.loc[config[\"test_start\"]+timedelta(days=day), agg]\n",
    "\n",
    "                except KeyError as e:\n",
    "                    num = df_train[agg].iloc[-1]\n",
    "\n",
    "                finally:\n",
    "\n",
    "                    _df = df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg]\n",
    "                    _df = _df.replace(_df.values, num)\n",
    "\n",
    "#                 print(df_test.loc[config[\"test_start\"]+timedelta(days=day):, agg], _df.values.ravel())\n",
    "\n",
    "                    df_test.loc[config[\"test_start\"]:, agg] = _df.values.ravel()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf71e08e",
   "metadata": {
    "code_folding": [
     18,
     23
    ]
   },
   "outputs": [],
   "source": [
    "def estimations(day, df_stats, y_pred_df, y_test, config):\n",
    "    \n",
    "    dates = y_test.index\n",
    "    \n",
    "    for date in dates:\n",
    "        step_day = int((date-(config[\"test_start\"]+timedelta(days=day))).days)\n",
    "\n",
    "        try:\n",
    "            pred = y_pred_df.loc[date, 0]\n",
    "            real = y_test.loc[date, config['target_column']]\n",
    "\n",
    "            err = abs(pred / real - 1) * 100\n",
    "\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_total_abs_error'] = np.round(abs(pred-real))\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_total_relative_error'] = np.round(abs(pred / real - 1), 4) * 100\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_more_5'] = 1 if (err > 5) else 0\n",
    "            df_stats.loc[date, f'd-{step_day}' + '_more_10'] = 1 if (err > 10) else 0\n",
    "            \n",
    "        except ZeroDivisionError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, :] = 0\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "\n",
    "            df_stats.loc[date, :] = 0\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664c8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(day, forecast_steps, y_pred_df, config, research_task_uuid):\n",
    "    \n",
    "    for step in range(forecast_steps+1):\n",
    "        try:\n",
    "            pred = y_pred_df.iloc[24*step:24*(step+1), 0].dropna().sort_index()\n",
    "            pred.index.name = 'date_time'\n",
    "\n",
    "            path_to_files = os.path.join(config['path_to_result'], \"forecast\", config['model_name'], \n",
    "                                         f\"research_task_{research_task_uuid}\", \n",
    "                                         f\"{config['model_name']}_{config['unique_uuid']}\")\n",
    "            if not os.path.isdir(path_to_files):\n",
    "                os.makedirs(path_to_files)\n",
    "                \n",
    "            file_name = os.path.join(path_to_files, \n",
    "                    f\"forecast_d-{step}_{config['model_name']}_{(config['test_start']+timedelta(days=day)).strftime('%Y-%m-%d')}_({pred.index[0].strftime('%Y-%m-%d')}).csv\")\n",
    "\n",
    "            pd.DataFrame(pred).to_csv(file_name)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41fc750",
   "metadata": {},
   "source": [
    "### wfv service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651890",
   "metadata": {},
   "source": [
    "#### *add train_features grid (day_means, date_features, lag_features etc.)\n",
    "\n",
    "#### *add checking LightGBM, Random_Forest, Linear_Classifier etc. \n",
    "\n",
    "#### *add lag_features (? check whats better: those or \"mean\"s) \n",
    "\n",
    "#### *am I able to add some factors like inflation/company's profit etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c32598ef",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_wfv(full_set: pd.DataFrame, config: dict, research_task_uuid: str, forecast_steps: int, models_dict: dict):\n",
    "    \n",
    "    X_full_set = full_set.loc[:, config['train_features']]\n",
    "    y_full_set = full_set.loc[:, [config['target_column']]]\n",
    "    \n",
    "    if X_full_set.shape[0] != y_full_set.shape[0]:\n",
    "        common_index = list(set(X_full_set.index) & set(y_full_set.index))\n",
    "        common_index.sort()\n",
    "        X_full_set = X_full_set.loc[common_index, :]\n",
    "        y_full_set = y_full_set.loc[common_index, :]\n",
    "    print(X_full_set.shape, y_full_set.shape)\n",
    "    \n",
    "\n",
    "    df_preds = pd.DataFrame()\n",
    "    df_stats = pd.DataFrame()\n",
    "\n",
    "    count_days = (test_end - test_start).days + 1\n",
    "    \n",
    "    \n",
    "    model_name = config['model_name']\n",
    "    print(model_name)\n",
    "    \n",
    "    model = config['model']\n",
    "\n",
    "    unique_uuid = config['unique_uuid']\n",
    "    \n",
    "    if not os.path.isdir(config['path_to_result']):\n",
    "        os.makedirs(config['path_to_result'])\n",
    "\n",
    "    path_folder_result = os.path.join(config['path_to_result'], \"wf_result\", model_name,\n",
    "                                      f\"research_task_{research_task_uuid}\")\n",
    "    if not os.path.isdir(path_folder_result):\n",
    "        os.makedirs(path_folder_result)\n",
    "        \n",
    "        \n",
    "\n",
    "    for day in tqdm(range(count_days)):\n",
    "        \n",
    "        \n",
    "        train_start = config.get('train_start', None)\n",
    "        if train_start is None:\n",
    "            if config.get('duration_training_history', None) is None:\n",
    "                train_start = X_full_set.index[0]\n",
    "                config['train_start'] = datetime(train_start.year, train_start.month, train_start.day)\n",
    "            else:\n",
    "                train_start = config['train_end'] + timedelta(days=i - config['duration_training_history'])\n",
    "\n",
    "        try:\n",
    "\n",
    "            X_train, X_test, y_train, y_test = data(day, X_full_set, y_full_set, train_start, config, forecast_steps)\n",
    "            X_test = standardize_mean_values(day, X_test.copy(), X_train, full_set, config)\n",
    "\n",
    "            y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "            y_pred_df = pd.DataFrame(y_pred, index=y_test.index)\n",
    "            \n",
    "            write_predictions(day, forecast_steps, y_pred_df, config, research_task_uuid)\n",
    "\n",
    "            df_stats = estimations(day, df_stats, y_pred_df, y_test, config)\n",
    "#             print('\\n\\n')\n",
    "        \n",
    "\n",
    "\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "\n",
    "    last_index = df_stats.index[-1]\n",
    "    df_stats.loc[last_index, 'model_hyperparameters'] = str(config['model_hyperparameters'])\n",
    "    df_stats.loc[last_index, 'train_features'] = str(config['train_features'])\n",
    "    \n",
    "    path_to_save_result_csv = os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.csv')\n",
    "    df_stats.round(2).to_csv(path_to_save_result_csv, date_format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    config_to_save = config.copy()\n",
    "    config_to_save.pop('model', None)\n",
    "    with open(os.path.join(path_folder_result, f'{model_name}_{unique_uuid}.yaml'), 'w') as outfile:\n",
    "        dump(config_to_save, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0650674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ends: 2025-08-31 23:00:00\t test starts: 2025-09-01 00:00:00\n",
      "_research_task_uuid = d7e4e374-9ca7-11f0-bd56-c0e434d84b22\n",
      "\n",
      "count_configs 369 \n",
      "\n",
      "xgboost == {'unique_uuid': 'd7e50a95-9ca7-11f0-a451-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a96-9ca7-11f0-bde0-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:06<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a97-9ca7-11f0-b0f9-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a98-9ca7-11f0-b17b-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a99-9ca7-11f0-83a7-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:09<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9a-9ca7-11f0-9832-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9b-9ca7-11f0-bd15-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:08<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9c-9ca7-11f0-9972-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:11<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9d-9ca7-11f0-ba32-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9e-9ca7-11f0-ab83-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:18<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50a9f-9ca7-11f0-ba00-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:25<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa0-9ca7-11f0-a331-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:17<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa1-9ca7-11f0-8779-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:56<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa2-9ca7-11f0-a035-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:40<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa3-9ca7-11f0-b5e4-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 5, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:30<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa4-9ca7-11f0-ad4a-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa5-9ca7-11f0-8766-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa6-9ca7-11f0-a7cc-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa7-9ca7-11f0-acdc-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:12<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa8-9ca7-11f0-9b68-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:09<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aa9-9ca7-11f0-85b3-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aaa-9ca7-11f0-bf62-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aab-9ca7-11f0-8830-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:16<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aac-9ca7-11f0-ae1b-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:11<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aad-9ca7-11f0-8176-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:39<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aae-9ca7-11f0-9438-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:34<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aaf-9ca7-11f0-937a-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:25<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab0-9ca7-11f0-95fb-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:24<00:00,  6.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab1-9ca7-11f0-b925-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:13<00:00,  5.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab2-9ca7-11f0-bacf-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=7, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 1000, 'n_jobs': -1, 'max_depth': 7, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:52<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab3-9ca7-11f0-bd7d-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:11<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab4-9ca7-11f0-a9a5-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab5-9ca7-11f0-b29c-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 50, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:07<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab6-9ca7-11f0-bf62-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:18<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab7-9ca7-11f0-9b08-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:16<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab8-9ca7-11f0-b4fd-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=100, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 100, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:11<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50ab9-9ca7-11f0-a559-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:33<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50aba-9ca7-11f0-8e7f-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:32<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50abb-9ca7-11f0-88f9-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 200, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:24<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50abc-9ca7-11f0-891e-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'temperature_min_3_years', 'temperature_max_3_years', 'temperature_mean_3_years', 'cloud_cover_mean_7_days', 'pressure_msl_mean_7_days'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 12) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:23<00:00,  5.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50abd-9ca7-11f0-bf28-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks', 'relative_humidity_min_7_days', 'temperature_min_7_days', 'temperature_mean_7_days', 'temperature_lag_168'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 11) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [01:05<00:00,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost == {'unique_uuid': 'd7e50abe-9ca7-11f0-b8a7-c0e434d84b22', 'train_start': datetime.datetime(2020, 1, 1, 0, 0), 'train_end': datetime.datetime(2025, 8, 31, 23, 0), 'test_start': datetime.datetime(2025, 9, 1, 0, 0), 'test_end': datetime.datetime(2025, 9, 14, 23, 0), 'target_column': 'temperature', 'train_features': ['month', 'year_day', 'is_day', 'sunshine_duration', 'temperature_min_3_weeks', 'temperature_max_3_weeks', 'temperature_mean_3_weeks'], 'path_to_result': '/masters_diploma/', 'forecast_days': 3, 'model_name': 'xgboost', 'model': XGBRegressor(base_score=None, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
      "             device=None, early_stopping_rounds=None, enable_categorical=False,\n",
      "             eta=0.3, eval_metric='rmse', feature_types=None, gamma=None,\n",
      "             grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
      "             num_parallel_tree=None, ...), 'model_hyperparameters': {'n_estimators': 500, 'n_jobs': -1, 'max_depth': 9, 'eta': 0.3, 'booster': 'gbtree', 'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'subsample': 1, 'colsample_bytree': 1, 'min_child_weight': 1, 'random_state': 2}} \n",
      "\n",
      "(93840, 7) (93840, 1)\n",
      "xgboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/14 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==\u001b[39m\u001b[38;5;124m'\u001b[39m, _, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m \u001b[43mrun_wfv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_research_task_uuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforecast_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 53\u001b[0m, in \u001b[0;36mrun_wfv\u001b[1;34m(full_set, config, research_task_uuid, forecast_steps, models_dict)\u001b[0m\n\u001b[0;32m     51\u001b[0m X_test \u001b[38;5;241m=\u001b[39m standardize_mean_values(day, X_test\u001b[38;5;241m.\u001b[39mcopy(), X_train, full_set, config)\n\u001b[1;32m---> 53\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     56\u001b[0m y_pred_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_pred, index\u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1081\u001b[0m (\n\u001b[0;32m   1082\u001b[0m     model,\n\u001b[0;32m   1083\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1089\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2144\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2144\u001b[0m         stb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_offset\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1448\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1339\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1338\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1186\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1189\u001b[0m colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1076\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1074\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1075\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1076\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1077\u001b[0m )\n\u001b[0;32m   1079\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1144\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1144\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:998\u001b[0m, in \u001b[0;36mgetmodule\u001b[1;34m(object, _filename)\u001b[0m\n\u001b[0;32m    997\u001b[0m _filesbymodname[modname] \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 998\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mgetabsfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:967\u001b[0m, in \u001b[0;36mgetabsfile\u001b[1;34m(object, _filename)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m     _filename \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m getfile(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormcase(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(_filename))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:949\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[1;32m<frozen genericpath>:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3493\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3492\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[1;32m-> 3493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[0;32m   3494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2165\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m-> 2165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2088\u001b[0m, in \u001b[0;36mInteractiveShell.get_exception_only\u001b[1;34m(self, exc_tuple)\u001b[0m\n\u001b[0;32m   2087\u001b[0m etype, value, tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_exc_info(exc_tuple)\n\u001b[1;32m-> 2088\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:156\u001b[0m, in \u001b[0;36mformat_exception_only\u001b[1;34m(exc, value)\u001b[0m\n\u001b[0;32m    155\u001b[0m     value \u001b[38;5;241m=\u001b[39m exc\n\u001b[1;32m--> 156\u001b[0m te \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(te\u001b[38;5;241m.\u001b[39mformat_exception_only())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:783\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, max_group_width, max_group_depth, _seen)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_context \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mid\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _seen):\n\u001b[1;32m--> 783\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__traceback__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_group_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_group_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_group_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_group_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_seen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_seen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:728\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, max_group_width, max_group_depth, _seen)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_group_depth \u001b[38;5;241m=\u001b[39m max_group_depth\n\u001b[1;32m--> 728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_walk_tb_with_full_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_traceback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type \u001b[38;5;241m=\u001b[39m exc_type\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:433\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 433\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:318\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03mUpdate the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:93\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2144\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2144\u001b[0m         stb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2145\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_offset\u001b[49m\n\u001b[0;32m   2146\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1448\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1339\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1338\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1186\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1189\u001b[0m colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1076\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1074\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1075\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1076\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1077\u001b[0m )\n\u001b[0;32m   1079\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1144\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1144\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:1001\u001b[0m, in \u001b[0;36mgetmodule\u001b[1;34m(object, _filename)\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         modulesbyfile[f] \u001b[38;5;241m=\u001b[39m modulesbyfile[\n\u001b[1;32m-> 1001\u001b[0m             \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m modulesbyfile:\n",
      "File \u001b[1;32m<frozen ntpath>:696\u001b[0m, in \u001b[0;36mrealpath\u001b[1;34m(path, strict)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m(coro)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3311\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_async\u001b[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[0;32m   3307\u001b[0m \u001b[38;5;66;03m# Execute the user code\u001b[39;00m\n\u001b[0;32m   3308\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[1;32m-> 3311\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[0;32m   3312\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[0;32m   3314\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n\u001b[0;32m   3315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_result \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3512\u001b[0m, in \u001b[0;36mInteractiveShell.run_ast_nodes\u001b[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[0;32m   3510\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m   3511\u001b[0m         result\u001b[38;5;241m.\u001b[39merror_before_exec \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 3512\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowtraceback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2165\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showtraceback(etype, value, stb)\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m-> 2165\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2088\u001b[0m, in \u001b[0;36mInteractiveShell.get_exception_only\u001b[1;34m(self, exc_tuple)\u001b[0m\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;124;03mReturn as a string (ending with a newline) the exception that\u001b[39;00m\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03mjust occurred, without any traceback.\u001b[39;00m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2087\u001b[0m etype, value, tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_exc_info(exc_tuple)\n\u001b[1;32m-> 2088\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:156\u001b[0m, in \u001b[0;36mformat_exception_only\u001b[1;34m(exc, value)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m _sentinel:\n\u001b[0;32m    155\u001b[0m     value \u001b[38;5;241m=\u001b[39m exc\n\u001b[1;32m--> 156\u001b[0m te \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(te\u001b[38;5;241m.\u001b[39mformat_exception_only())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:783\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, max_group_width, max_group_depth, _seen)\u001b[0m\n\u001b[0;32m    780\u001b[0m     need_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_context \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mid\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _seen):\n\u001b[1;32m--> 783\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__traceback__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_group_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_group_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_group_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_group_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_seen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_seen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:728\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, max_group_width, max_group_depth, _seen)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_group_width \u001b[38;5;241m=\u001b[39m max_group_width\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_group_depth \u001b[38;5;241m=\u001b[39m max_group_depth\n\u001b[1;32m--> 728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_from_extended_frame_gen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_walk_tb_with_full_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_traceback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type \u001b[38;5;241m=\u001b[39m exc_type\n\u001b[0;32m    733\u001b[0m \u001b[38;5;66;03m# Capture now to permit freeing resources: only complication is in the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;66;03m# unofficial API _format_final_exc_line\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:433\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 433\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:318\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtokenize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    137\u001b[0m         lines \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m, \u001b[38;5;167;01mSyntaxError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\tokenize.py:396\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(filename):\n\u001b[0;32m    393\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    detect_encoding().\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 396\u001b[0m     buffer \u001b[38;5;241m=\u001b[39m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m         encoding, lines \u001b[38;5;241m=\u001b[39m detect_encoding(buffer\u001b[38;5;241m.\u001b[39mreadline)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models_list = ['XGBoost', 'LightGBM', 'Random_Forest']    #'Prophet'\n",
    "models_dict = dict([(\"\".join(re.findall('([A-Z])', k)).lower(), k.lower()) for k in models_list])\n",
    "\n",
    "forecast_steps = 3        # means that forecast will be made on {n} futute days \n",
    " \n",
    "\n",
    "full_set, train_end, test_start, test_end, train_features_set = init()\n",
    "print(f'train ends: {train_end}\\t test starts: {test_start}')\n",
    "\n",
    "_research_task_uuid = str(uuid.uuid1())\n",
    "print(f'_research_task_uuid = {_research_task_uuid}\\n')\n",
    "\n",
    "configs = define_parameters(train_end, test_start, test_end, train_features_set, forecast_steps, models_dict)\n",
    "print(f'count_configs {len(configs)} \\n')\n",
    "\n",
    "for _ in configs:\n",
    "    print(_['model_name'], '==', _, '\\n')\n",
    "\n",
    "    run_wfv(full_set, _, _research_task_uuid, forecast_steps, models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832db5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy2('wfv.ipynb', f'/masters_diploma/archive/wfv_{str(uuid.uuid1())}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
